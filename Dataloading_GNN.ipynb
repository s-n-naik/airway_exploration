{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01ce9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "# !apt-get install -y xvfb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cf9cd",
   "metadata": {},
   "source": [
    "## LOAD FILE W WEIBEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the e5 csv and add weibel gen (if uncommented)\n",
    "# orig_df = pd.read_csv(os.path.abspath(\"/home/sneha/e5lungairwaysvida_20140211.csv\"))\n",
    "orig_df = pd.read_csv(os.path.abspath('/home/sneha/e5lungairwaysvida_20140211_weibel.csv')) # original + weibel gen added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500329a7",
   "metadata": {},
   "source": [
    "## Remove scan problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60968966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE SCAN PROBLEM\n",
    "ids_w_scan_problem = orig_df.loc[orig_df.scan_problem != 0].idno.unique()\n",
    "print(f\"There are {len(ids_w_scan_problem)} ids with san problems --> remove them\")\n",
    "orig_df = orig_df.loc[~(orig_df.idno.isin(ids_w_scan_problem))]\n",
    "print(f\"There are {orig_df.idno.nunique()} remaining participants\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847d746",
   "metadata": {},
   "source": [
    "## Remove nans in startbpid / endbpid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE NANS in START + ENDBPID\n",
    "orig_df.dropna(subset=['startbpid', 'endbpid'], inplace=True)\n",
    "print(f\"There are {orig_df.idno.nunique()} remaining participants after dropping NaNs in start/endbpid\")\n",
    "# print null\n",
    "orig_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112228e4",
   "metadata": {},
   "source": [
    "## Remove unneccesary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneccesary cols\n",
    "\n",
    "useful_cols = ['idno',\n",
    " 'anatomicalname',\n",
    " 'centerlinelength','avginnerarea','lobe',\n",
    " 'sublobe',\n",
    " 'endbpid',\n",
    " 'startbpid',\n",
    " 'angle',\n",
    " 'dircosx',\n",
    " 'dircosy',\n",
    " 'dircosz', 'weibel_generation']\n",
    "\n",
    "orig_df = orig_df[useful_cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ab6b2",
   "metadata": {},
   "source": [
    "## QC paths only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP ONLY QC PATHS\n",
    "qc_names = [x for x in orig_df.anatomicalname.unique() if ('unnamed' not in x.lower()) & (x != '-')]\n",
    "orig_df['QC'] = False\n",
    "\n",
    "print(qc_names)\n",
    "orig_df.loc[orig_df.anatomicalname.isin(qc_names), 'QC'] = True\n",
    "display(orig_df)\n",
    "\n",
    "def _travel_two(df, extend_names=['LB1', 'LB10', 'RB1', 'RB4', 'RB10'], extend_gen=2):\n",
    "    print('start',df.QC.sum())\n",
    "    startbpids = df.loc[df.anatomicalname.isin(extend_names)]['endbpid'].to_list()\n",
    "    print(f\"Extending {extend_gen} generations from {extend_names} which have segment ids = {startbpids}\")\n",
    "    qc_children = startbpids\n",
    "    for i in range(extend_gen):\n",
    "        new_children = df.loc[df.startbpid.isin(qc_children)]['endbpid'].to_list()\n",
    "        qc_children+=new_children\n",
    "#         print('Adding a generation', qc_children)\n",
    "    print('end', len(qc_children))\n",
    "    return qc_children\n",
    "    \n",
    "          \n",
    "          \n",
    "for i, participant_df in tqdm(orig_df.groupby('idno')):\n",
    "    print(participant_df.idno.unique())\n",
    "    qc_children = _travel_two(participant_df,extend_names=['LB1', 'LB10', 'RB1', 'RB4', 'RB10'], extend_gen=2)\n",
    "    orig_df.loc[(orig_df.idno==int(participant_df.idno.unique())) & (orig_df.endbpid.isin(qc_children)), 'QC']= True\n",
    "\n",
    "display(orig_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359cc95",
   "metadata": {},
   "source": [
    "## Remove all orphans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35665884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_orphans(df):\n",
    "    orphan_check = np.zeros_like(df.endbpid.values, dtype=bool)\n",
    "    groups = df.groupby('idno')\n",
    "    i = 0\n",
    "    for name, group in tqdm(groups, desc='Iterating ids'):\n",
    "        orphan_check[i:i+len(group)] =\\\n",
    "        np.isin(group.startbpid.values, group.endbpid.values) | \\\n",
    "        (group.startbpid == -1)\n",
    "        i = i+len(group)\n",
    "    return orphan_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_orphans(orig_df):\n",
    "    there_are_orphans = True\n",
    "    i = 0\n",
    "    while there_are_orphans:\n",
    "        i+=1\n",
    "        \n",
    "        orphan_check = _remove_orphans(orig_df)\n",
    "        num_orphan = (orphan_check==0).sum()\n",
    "        \n",
    "        if num_orphan ==0:\n",
    "            print(f\"Iter {i}: THERE ARE NO ORPHANS\")\n",
    "            there_are_orphans = False\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Iter {i}:There are {num_orphan} orphans, REMOVING THEM\")\n",
    "            orig_df = orig_df.loc[orphan_check]\n",
    "            print(f\"Df length {len(orig_df)}\")\n",
    "    return orig_df\n",
    "\n",
    "\n",
    "df_no_orphans = remove_all_orphans(orig_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea39cb7",
   "metadata": {},
   "source": [
    "## Add coords of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4da685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD COorodinates\n",
    "\n",
    "def _get_coords(single_test, start_x=0, start_y=0,start_z=0, start_loc=-1, x_sf=1, y_sf=1, z_sf=1):\n",
    "    '''\n",
    "    single_test: single participant tree dataframe\n",
    "    startx/y/z: coords of carina to start\n",
    "    start_loc: 1 = endbpid corresponding to startx,y,z 1=carina, -1 = top of trachea  \n",
    "    x/y/z_sf: scale factors based on voxel dimensions mm    \n",
    "    \n",
    "    '''\n",
    "    assert single_test.startbpid.min() == start_loc, 'The dataframe entered has rows before start_loc'\n",
    "    # gets coords of ENDBPID\n",
    "    # THIS HAS -1 on the Y!\n",
    "    # delta x, delta y, delta z for each of the segments --> scaled by pixel scale factor to get to 1:1:1 visualisation\n",
    "    x_diff= (single_test.centerlinelength*single_test.dircosx/x_sf).values\n",
    "    # running without minus\n",
    "    y_diff = (single_test.centerlinelength*single_test.dircosy/y_sf).values\n",
    "    z_diff = (single_test.centerlinelength*single_test.dircosz/z_sf).values\n",
    "    endbpid = single_test.endbpid.values\n",
    "    idno = single_test.idno.values\n",
    "    startbpid = single_test.startbpid.values\n",
    "#     print(list(zip(endbpid, x_diff, y_diff, z_diff)))\n",
    "    \n",
    "    x = np.zeros_like(x_diff)\n",
    "    y = np.zeros_like(x_diff)\n",
    "    z = np.zeros_like(x_diff)\n",
    "    # for each segment, if we're at the start location, add start location to delta x,y,z\n",
    "    # otherwise, find the parent x,y,z value (done sequentially) and add on parent location\n",
    "    for i in range(len(endbpid)):\n",
    "        if startbpid[i] == start_loc:\n",
    "            print(\"adding start loc\", start_x, start_y, start_z)\n",
    "            x[i] = x_diff[i] + start_x\n",
    "            y[i] = y_diff[i] + start_y\n",
    "            z[i] = z_diff[i] + start_z\n",
    "            print(i, x[i], y[i], z[i])\n",
    "        else:\n",
    "            # find parent endbpid and get the corresponding x,y,z\n",
    "            parent = np.where(endbpid == startbpid[i])\n",
    "            print('parent',parent)\n",
    "            x[i] = x_diff[i] + x[parent] \n",
    "            y[i] = y_diff[i] + y[parent] \n",
    "            z[i] = z_diff[i] + z[parent] \n",
    "#             print(\"parent\", parent, \"i\", i, x[i], y[i], z[i])\n",
    "    # put into dataframe\n",
    "    coords_df = pd.DataFrame({\"idno\": idno, \"endbpid\": endbpid, \"x\": x, \"y\": y, \"z\":z})\n",
    "#     tree_w_coords= single_test.merge(coords_df, how=\"left\", on='endbpid')\n",
    "    return single_test.merge(coords_df, how=\"left\", on='endbpid')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_no_orphans.groupby('idno')\n",
    "\n",
    "name, group = next(groups)\n",
    "print(name, group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc34c7",
   "metadata": {},
   "source": [
    "## Save file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
